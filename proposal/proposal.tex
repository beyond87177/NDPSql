\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{fullpage}
\usepackage{amsmath}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{hyperref}
\hypersetup{colorlinks=true,linktoc=all}
\usepackage{listing}
\usepackage{subcaption}
\usepackage[table]{xcolor}
\usepackage{multirow}
\usepackage{cleveref}
\usepackage{xspace}

\newcommand{\filter}{\textit{Filter}\xspace}
\newcommand{\projection}{\textit{Projection}\xspace}
\newcommand{\join}{\textit{Join}\xspace}
\newcommand{\sort}{\textit{Sort}\xspace}
\newcommand{\indexing}{\textit{Indexing}\xspace}
\newcommand{\groupby}{\textit{Group By}\xspace}
\newcommand{\topk}{\textit{TopK}\xspace}


\title{In-Storage SQL Processing\\
  \large MIT CSAIL Joint Research Proposal} \author{Shuotao Xu, Xiangyao Yu\\
  CSG Group, DB Group\\
  (shuotao@csail.mit.edu), (yxy@csail.mit.edu)}

\begin{document}
\maketitle
\section{Introduction}
With the ever-growing data collected and available, technology for fast and efficient data storage is becoming increasingly crucial for supporting complex queries on large datasets.
For big-data applications, a large number of analytic platforms rely on relational database systems, such as MySQL and Postgres, to store large datasets and running complex SQL queries.
An SQL database system brings data from the flash disks via the interconnecting storage network to the CPU cache to perform analysis of the fetched data.

With today's technology advancement, the storage network I/O bandwidth can be imbalanced with the aggregate secondary storage bandwidth, and become a bottleneck for fast SQL processing.
Such a scenario can be true for both a single server and a cluster of servers for SQL processing.
On a single server node, a flash disk is typically connected via 4 lanes of PCIe gen3 bus, which provide 4GB/s of bandwidth.
The flash chips inside a flash disk can provide a internal aggregate bandwidth which is much greater than the PCIe gen3 bus, if they are organized in a parallel architecture.
Therefore, SQL processing on a single node can be bottlenecked by the PCIe bus bandwidth.
On the other hand, on the cluster of servers performing distributed SQL analysis, compute and storage components are typically separated on different physical servers, such as the Amazon cloud.
With such a compute and storage separation in a cloud, the distributed SQL processing performance can be also held up by the slow server network speed.

In today's flash storage technology development, industry as well as academia are trying to enable some in-storage computational capabilities, such as ARM processors and FPGAs, to application developers.
In this research, we want to investigate how to use such in-storage computation hardware to offload some of the SQL operators inside flash drives to boost SQL query performance.
We propose to investigate 7 important SQL operators for the benefits of in-storage processing: \filter, \projection, \join, \sort, \indexing, \groupby, and \topk.
We will devise new techniques to implement those operators on inside storage due to limited computation and DRAM size.
We assume that the IO-intensive operators such as \filter, \projection, \join, \sort, \groupby and \topk  will benefit the most from in-storage processing.
Operators, such as \sort, are compute-bound, which we assume will not benefit from in-storage computing.

Specifically, the proposed research will make the following contributions.

\begin{itemize}
\item We extensively study the widely used operators in SQL-based relational databases. For each operator, we conduct a qualitative analysis of whether it can benefit from near-storage computing. 

\item We design and optimize these operators in a near-storage computing platform and demonstrate a significant reduction in IO traffic and CPU computation time. 

\item We incorporate the design into an open-source database, SQLite, and evaluate the performance advantage of each optimization we propose. 
\end{itemize}

Please note that this MIT internal collaboration between Computer Structure Group and Database Group has been started prior to the Samsung Internship. And we are interested in pursuing this research in an open-source domain.


\section{System Architecture}

A relational query processor takes a declarative SQL statement, validates it, optimizes it into a procedural dataflow execution plan, and execute that dataflow program on behalf of a client.
A relational query processor typically have four major software components 1) Query Parser, 2) Query Rewriter, 3) Query Optimizer and 4) Plan Executor.
The first three components generate a query plan, and the Plan Executor then issues disk IOs to the storage device, and execute the plan as shown in Figure~\ref{fig:software}.
In this proposal, we want to modify the Plan Executor such that it adds a side channel to the storage device.
Via this side channel, IO-intensive operations can be offloaded to the accelerators in the flash drive, as shown in Figure~\ref{fig:accelerator}.
As a result of such a in-storage accelerator architecture, 1) the total IOs between the processor and storage are dramatically reduced, and 2) accelerators can utilize the entire aggregate internal NAND flash bandwidth.

\begin{figure}[!htb]
  \centering
    \begin{subfigure}[t]{0.40\textwidth}
      \includegraphics[width=\textwidth]{figures/software-stack-crop.pdf}
      \caption{Traditional Query processing stack}
      \label{fig:software}
  \end{subfigure}\hspace{5pt}
  \begin{subfigure}[t]{0.40\textwidth}
    \includegraphics[width=\textwidth]{figures/accelerator-stack-crop.pdf}
    \caption{Query processing stack with In-storage Accelerators}
    \label{fig:accelerator}
  \end{subfigure}
  \label{fig:try}
  \caption{DBMS Query Processing Architectures}
\end{figure}

\section{SQL Operators}

We want to investigate 7 operators for their amenability for near-data processing.

In this section, we analyze the most commonly used operators in a database qualitatively and discusses whether they are amenable to near-data computing (\cref{sec:analysis}). Then, we discuss how each individual operators can be performed using NDP from Section~\ref{sec:xxx} to \ref{sec:xxx}. 

\subsection{Qualitative Analysis of Operators} \label{sec:analysis}

Table~\ref{tab:operators} presents seven operators that are commonly used in a database. For each operator, we present the average time complexity for a typical implementation, the worse case space complexity, and whether the operator is amenable to NDP. If the operator is on a single table, $N$ represents the size of that table; if the operator is on two tables, $N$ ($M$) represents the size of the smaller (bigger) table. For the \textit{Group By} operator, $K$ is the number of groups. For the \textit{TopK} operator, $K$ is the number of records selected. 

\begin{table}
\centering 
\begin{tabular}{ |c|c|c|c| } 
 \hline
 Operator       & Time Complexity & Space Complexity  & Amenable to NDP \\ \hline
 \filter        & $\Theta(N)$     & $\Theta(1)$       & Yes             \\ \hline
 \projection    & $\Theta(N)$     & $\Theta(1)$       & Yes             \\ \hline
 \join          & $\Theta(M + N)$ & $\Theta(N)$       & Yes (Partial)   \\ \hline
 \groupby       & $\Theta(N)$     & $\Theta(K)$       & Yes (Partial)   \\ \hline
 \indexing      & $\Theta(\log{N})$ & $\Theta(N)$     & Yes             \\ \hline
 \topk          & $\Theta(N\log{K})$ & $\Theta(K)$    & Yes (Partial)   \\ \hline
 \sort          & $\Theta(N\log{N})$ & $\Theta(\log{N})$ & No           \\ \hline
\end{tabular}
\caption{Comparison of common SQL operators.}
\label{tab:operators}
\end{table}

In particular, we propose to offload two important IO-intensive SQL functions inside the in-storage accelerators, Aggregate and JOIN.


\subsection{Filter and Projection}

A filter operator will filter out database rows based on the predicate.
Likewise a projection operator will take the selected columns from database rows.
The computation of the filter and projection operators only needs one pass of the data and has little DRAM requirement.
Thus, it is straightforward to implement on in-storage processing unit.
Such a work has been extensively explored by work such as IBM Nettezza~\cite{netezza}.

\subsection{Join}

An SQL JOIN operation combines columns from one or more tables in a relational database.
A popular implementation of JOIN operations uses the hash join algorithm.
JOIN is typically IO-intensive operations because all rows of the joining tables have to be read from the secondary storage.

As show in Figure~\ref{fig:hash-join}, to hash-join Table A and B, a hash table is first constructed with values of the departmentID column in table A.
Then the values of the departmentID column in table B are fetched to find a match in the hash table.
Such an algorithm requires all the data records to be retrieved from the secondary storage to CPU.

We propose accelerator for hash-join which implements a in-storage bloom-filter in datapath as shown in Figure~\ref{fig:filter-hash-join}.
When rows of table A is read from flash to CPU for the hash table construction, it constructs a bloom-filter in the datapath.
When the rows of table B are streamed from flash to join the hash table, they are filtered with the constructed bloom filter before sending to CPU.
If the bloom-filter selectivity is high, i.e., only a relatively few rows need to be joined, such a mechanism can greatly reduced required IO from storage to CPU.

\begin{figure}[!htb]
  \centering
  \begin{subfigure}[t]{0.48\textwidth}
    \includegraphics[width=\textwidth]{figures/hash-join-crop.pdf}
      \caption{Hash-join Operations without accelerators}
      \label{fig:hash-join}
  \end{subfigure}
  \begin{subfigure}[t]{0.48\textwidth}
    \includegraphics[width=\textwidth]{figures/filter-hash-join-crop.pdf}
    \caption{Accelerated Hash-join Operations with In-storage Bloom filter}
    \label{fig:filter-hash-join}
  \end{subfigure}
  \label{fig:try}
  \caption{Hash-join Operations}
\end{figure}

\subsection{Group-By Aggregate}

Aggregate functions are often used with \groupby database operations, where rows are grouped based on column values and each group of rows is summarized by applying the aggregate functions.
When number of groups are much smaller than total number of rows in a table, storage IO can be greatly reduced by offloading aggregate functions with GROUPBY to the flash drive.
Previous work, Ibex~\cite{ibex} has investigated how aggregate group-by works on FPGA.

\subsection{TopK Accelerator}

\subsection{Index Probing Accelerator}

%% \subsection{Sort Accelerator}


\section{Evaluation Benchmarks}
\label{sec:eval}
To evaluate the work, we propose to run some synthetic SQL queries with aggregate functions and join, as well as some queries from TPC-H, and TPC-DS.
By comparing the same query on the same dataset running on the traditional relational database systems, such as MySQL and Postgres, we can illustrate the performance benefits of the new architecture with accelerators.

Below are examples of SQL queries we plan to evaluate.

\begin{enumerate}

\item Query A: Synthetic query for evaluating aggregate accelerator 
\begin{verbatim}
SELECT department, years in company, SUM(salary) as sal sum
FROM employee GROUP BY department, years_in_company
\end{verbatim}

\item Query B: Modified Q14 of TPC-H for evaluating hash-join accelerator
\begin{verbatim}
SELECT sum(l_extendedprice * (1-l_discount)) as promo_revenue
FROM lineitem, part
WHERE l_partkey = p_partkey
and l_shipdate >= 1995-09-01 
and l_shipdate < 1995-10-01
\end{verbatim}

\item Query C: Q52 of TPC-DS for evaluating complex queries by both accelerators
\begin{verbatim}
SELECT dt.d_year, item.i_brand_id brand_id, item.i_brand brand,
SUM(ss_ext_sales_price) ext_price
FROM date_dim dt, store sales, item
WHERE dt.d date sk = store sales.ss sold date sk AND
store sales.ss item sk = item.i item sk AND
item.i manager id = 1 AND dt.d moy = 11 AND dt.d year = 2000
GROUP BY dt.d year, item.i brand, item.i brand id
ORDER BY dt.d year, ext price DESC, brand id
\end{verbatim}
\end{enumerate}

\bibliographystyle{abbrv}
\bibliography{reference}

\end{document}



